{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_2a",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmYdiAf4dL1X+4ZBNyLDkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Precillieo/Tensorflow-Computer-Vision-/blob/neunet/Tensorflow_2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pTw-VBcHGwO"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Pertaining to the Tensorflow_1 file where we carried out of tensorflow installation, its fundamentals and basics, variable creation, basic calculations, enabling eager execution, operation overloading, Fizzbuzz writing, variable and optimizers as object, saving and loading models as object, finally, building and training a multi-layers model. \n",
        "\n",
        "At this stage of our learning, we'd be talking about what is needed to be known by DS and ML Engineers aiming to build Deep Learning Neural Networks for both regression and classification problems:\n",
        "\n",
        "* **Activation Functions**:\n",
        "  * Regression Problem:\n",
        "    * Rectified Linear Units(Relu)\n",
        "    * Exponential Linear Units\n",
        "\n",
        "  * Classification Problem:\n",
        "    * Sigmoid\n",
        "\n",
        "* **Loss Functions**:\n",
        "  * Regression Problems:\n",
        "    * Mean Square Error\n",
        "    * Mean Percentage Absolute Error\n",
        "    * Mean Percentage Error\n",
        "\n",
        "  * Classification Problem:\n",
        "    * Binary Cross Entropy\n",
        "    * Categorical Cross Entropy\n",
        "    * Cosine Similarity\n",
        "\n",
        "* **Optimizers**:\n",
        "  * Regression Problems:\n",
        "    * Stochastic Gradient Descent\n",
        "\n",
        "  * Classification Problems:\n",
        "    * Adams\n",
        "    * RMSProp\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIod1Z1FOj_j"
      },
      "source": [
        "## Activation Functions\n",
        "\n",
        "These are functions that engages each neuron cell in active learning of patterns between input data and its corresponding target data. Meaning, computational functions for neuron computation and interaction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOyISAaoPQHz"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "Mathematical algorithms that helps measure how close a neural net learns to getting the actual result. It evaluates the performance of an ML algorithm with respect to its desired result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoNefKgkPu-f"
      },
      "source": [
        "## Optimizers\n",
        "\n",
        "An algorithm that helps another algorithm to reach its peak performance without delay. It hasten the converging of Loss function as well as reducing the posibility of gradient explosion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWeKHdjaQs3d"
      },
      "source": [
        "**Check Tensorflow_2b and Tensorflow_2c for the code example for Classification and Regression Problems respectively**"
      ]
    }
  ]
}